#=============================================================================
# Terraform Variables Example
# Copy to terraform.tfvars and customize. KEEP SENSITIVE VALUES OUT OF GIT.
#=============================================================================

#-----------------------------------------------------------------------------
# ENVIRONMENT
#-----------------------------------------------------------------------------
environment = "dev"  # dev | staging | prod

#-----------------------------------------------------------------------------
# GCP CONFIGURATION (REQUIRED)
#-----------------------------------------------------------------------------
gcp_project_id = "your-gcp-project-id"   # REQUIRED: GCP project ID
gcp_region     = "us-central1"           # Region for GKE / Cloud SQL
gcp_zones      = ["us-central1-a", "us-central1-b"]  # Multi-zone GKE

#-----------------------------------------------------------------------------
# GKE CONFIGURATION
#-----------------------------------------------------------------------------
gke_node_count   = 2                # Nodes per zone
gke_machine_type = "e2-standard-4"  # Machine type (e.g., e2-standard-4, n1-standard-2)
gke_disk_size_gb = 50               # Boot disk size per node (GB) (10-2000)
gke_disk_type    = "pd-standard"     # Disk type: pd-standard | pd-ssd (pd-standard saves quota)

#-----------------------------------------------------------------------------
# AWS CONFIGURATION
#-----------------------------------------------------------------------------
aws_region               = "us-east-1"
aws_vpc_cidr             = "10.50.0.0/16"
aws_private_subnet_cidrs = ["10.50.1.0/24", "10.50.2.0/24"]

#-----------------------------------------------------------------------------
# CLOUD SQL CONFIGURATION
#-----------------------------------------------------------------------------
cloudsql_tier    = "db-custom-1-3840"  # See variables.tf for defaults
cloudsql_version = "POSTGRES_15"

#-----------------------------------------------------------------------------
# OPTIONAL S3 BUCKET NAMES (auto-generated if null)
#-----------------------------------------------------------------------------
# submission_bucket_name = "my-project-submissions"
# checkpoint_bucket_name = "my-project-flink-checkpoints"

#-----------------------------------------------------------------------------
# AWS LAMBDA (PDF Extraction)
#-----------------------------------------------------------------------------
lambda_deployment_bucket = "your-lambda-artifacts-bucket"      # Bucket with ZIP
lambda_deployment_key    = "lambda/submission_pdf_extract.zip" # Key to ZIP

#-----------------------------------------------------------------------------
# APACHE FLINK (REQUIRED BEFORE aws_managed_flink MODULE APPLY)
#-----------------------------------------------------------------------------
# Upload shaded JAR first: aws s3 cp target/analytics-flink-job-1.0.0-shaded.jar s3://your-bucket/flink/analytics-flink-job-1.0.0.jar
flink_job_jar = "s3://your-flink-artifacts-bucket/flink/analytics-flink-job-1.0.0.jar"

#-----------------------------------------------------------------------------
# KAFKA TOPICS (Align with README event flow)
#-----------------------------------------------------------------------------
kafka_topics = [
  "paper_uploaded",
  "paper_uploaded_processed",
  "plagiarism_checked",
  "plagiarism_checked_processed",
  "analytics_window"
]

#-----------------------------------------------------------------------------
# ARGOCD CONFIGURATION
#-----------------------------------------------------------------------------
argocd_version = "5.51.3"  # Keep in sync with variables.tf default

#-----------------------------------------------------------------------------
# GATEWAY INGRESS HOST (blank = use LB/IP)
#-----------------------------------------------------------------------------
gateway_host = ""

#-----------------------------------------------------------------------------
# FEATURE FLAGS
#-----------------------------------------------------------------------------
enable_firewall_rules = true

#-----------------------------------------------------------------------------
# NOTES
#-----------------------------------------------------------------------------
# 1. Rename this file to terraform.tfvars.
# 2. Never commit terraform.tfvars.
# 3. Sequence: apply -target=module.gke -> gcloud get-credentials -> terraform apply (rest).
# 4. Ensure flink_job_jar & lambda_deployment_key artifacts exist in S3 before targeting related modules.
# 5. Update k8s/base/configmap.yaml with outputs (e.g., cloudsql instance connection name) after apply.
